# ===============================
# 1. å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# ===============================
import streamlit as st
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import foolbox as fb
import urllib.request
import io

# ===============================
# 2. ã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜
# ===============================
st.title("ğŸ”’ PGDæ”»æ’ƒãƒ‡ãƒ¢")
#st.write("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€PGDæ”»æ’ƒã«ã‚ˆã‚Šåˆ†é¡ãŒã©ã®ã‚ˆã†ã«å¤‰åŒ–ã™ã‚‹ã‹ã‚’ç¢ºèªã§ãã¾ã™ã€‚")

# ===============================
# 3. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ===============================
uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆJPEG/PNGï¼‰", type=["jpg", "jpeg", "png"])
if uploaded_file is not None:
    image = Image.open(uploaded_file).convert('RGB')

    # ===============================
    # 4. å‰å‡¦ç†
    # ===============================
    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
    ])
    input_tensor = transform(image).unsqueeze(0)

    # ===============================
    # 5. ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒã‚¤ã‚¹
    # ===============================
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = models.resnet50(pretrained=True).to(device).eval()
    input_tensor = input_tensor.to(device)
    fmodel = fb.PyTorchModel(model, bounds=(0, 1), device=device)

    # ===============================
    # 6. ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®èª­ã¿è¾¼ã¿
    # ===============================
    url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
    categories = urllib.request.urlopen(url).read().decode("utf-8").splitlines()

    # ===============================
    # 7. å…ƒãƒ©ãƒ™ãƒ«ã®äºˆæ¸¬
    # ===============================
    logits = model(input_tensor)
    label = logits.argmax(dim=1).item()
    label_name = categories[label]

    # ===============================
    # 8. PGDæ”»æ’ƒ
    # ===============================
    attack = fb.attacks.LinfPGD(steps=40, rel_stepsize=0.05, random_start=True)
    epsilons = 0.03
    raw_adv, clipped_adv, is_adv = attack(fmodel, input_tensor, torch.tensor([label]).to(device), epsilons=epsilons)

    # æ•µå¯¾ãƒ©ãƒ™ãƒ«ã®å–å¾—
    adv_output = model(clipped_adv)
    adv_label = adv_output.argmax(dim=1).item()
    adv_label_name = categories[adv_label]

    # ===============================
    # 9. ãƒã‚¤ã‚ºç”»åƒã®å¯è¦–åŒ–
    # ===============================
    noise = clipped_adv - input_tensor
    noise_abs = (noise - noise.min()) / (noise.max() - noise.min())

    # ===============================
    # 10. è¡¨ç¤ºé–¢æ•°
    # ===============================
    def tensor_to_img(tensor):
        img = tensor.squeeze().detach().cpu().permute(1, 2, 0).numpy()
        return np.clip(img, 0, 1)

    # ===============================
    # ğŸ” 11. çµæœè¡¨ç¤º
    # ===============================
    st.subheader("ğŸ¯ åˆ†é¡çµæœ")
    st.write(f"**å…ƒã®ãƒ©ãƒ™ãƒ«:** {label_name}")
    st.write(f"**æ”»æ’ƒå¾Œãƒ©ãƒ™ãƒ«:** {adv_label_name} ï¼ˆæˆåŠŸ: {bool(is_adv.item())}ï¼‰")

    st.subheader("ğŸ–¼ï¸ ç”»åƒè¡¨ç¤º")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.image(tensor_to_img(input_tensor), caption=f"Original: {label_name}", use_container_width=True)

    with col2:
        st.image(tensor_to_img(clipped_adv), caption=f"PGD Adversarial: {adv_label_name}", use_container_width=True)

    with col3:
        st.image(tensor_to_img(noise_abs), caption="Noise", use_container_width=True)
